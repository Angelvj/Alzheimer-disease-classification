{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelvj/TFG/blob/main/code/jupyter/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZf1JmliAMNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39faf9c7-288f-4b77-e09a-5a64e22ae1a1"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras as k\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  DATA_PATH = '/content/drive/My Drive/Machine learning/data'\n",
        "\n",
        "else: \n",
        "  DATA_PATH = '../../data'\n",
        "\n",
        "def load_image(filename):    \n",
        "    \"\"\"\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        relative path to de image\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    img : numpy ndarray\n",
        "        array containing the image\n",
        "        \n",
        "    \"\"\"\n",
        "    img = nib.load(filename)\n",
        "    img = np.asarray(img.dataobj)\n",
        "    img = np.expand_dims(img, axis=3)\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_images_from_dir(dirname):\n",
        "    \"\"\"\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dirname : str\n",
        "        name of the directory containing images.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    imgs : numpy ndarray\n",
        "        array containing all of the images in the folder.\n",
        "\n",
        "    \"\"\"\n",
        "    imgs = []\n",
        "\n",
        "    for filename in tqdm(glob.glob(dirname + '/*.nii')):\n",
        "        imgs.append(load_image(filename))\n",
        "        \n",
        "    imgs = np.stack(imgs)\n",
        "    return imgs\n",
        "\n",
        "def load_data(dirs_dict):\n",
        "    \"\"\"\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dirs_dict : dictionary\n",
        "        dictionary containing data folders name, and the label for the images\n",
        "        on each forlder.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x : numpy ndarray\n",
        "        array containing the images.\n",
        "    y : numpy ndarray\n",
        "        array containig the label of each image.\n",
        "\n",
        "    \"\"\"\n",
        "    first = True\n",
        "    for key, value in dirs_dict.items():\n",
        "        if first:\n",
        "            X = load_images_from_dir(value)\n",
        "            y = np.full((X.shape[0]), key, dtype=np.uint8)\n",
        "            first = False\n",
        "        else:\n",
        "            X_current = load_images_from_dir(value)\n",
        "            X = np.concatenate((X, X_current))\n",
        "            y = np.concatenate((y, np.full((X_current.shape[0]), key, dtype=np.uint8)))\n",
        "            \n",
        "    y = k.utils.to_categorical(y)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "def impute_nan_values(imgs, inplace=True):\n",
        "    return np.nan_to_num(imgs, copy= not inplace)\n",
        "\n",
        "# Load PET images with labels\n",
        "print('\\n --- Loading PET data --- \\n')\n",
        "time.sleep(0.5)\n",
        "X, y = load_data({0: DATA_PATH + \"/ppNOR/PET\", \n",
        "                  1: DATA_PATH + \"/ppAD/PET\",\n",
        "                  2: DATA_PATH + \"/ppMCI/PET\"})\n",
        "\n",
        "# Separate into training and test sets (stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.2, stratify = y, random_state = 1)\n",
        "\n",
        "\n",
        "impute_nan_values(X_train)\n",
        "impute_nan_values(X_test)\n",
        "\n",
        "print('\\n --- PET data loaded --- \\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            " --- Loading PET data --- \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:37<00:00,  1.81it/s]\n",
            " 27%|██▋       | 19/70 [00:10<00:39,  1.28it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yCcZQKccaYm"
      },
      "source": [
        "# N-fold cross-validation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__EGiOvl5IjU",
        "outputId": "2727386f-ac26-4e1c-acfb-7e83e72e4394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 33% de cada tipo en test\n",
        "print(np.sum(y_test, axis=0))\n",
        "\n",
        "\n",
        "\n",
        "# basic 3D cnn model\n",
        "\n",
        "# Model configuration\n",
        "batch_size = 5\n",
        "no_epochs = 10\n",
        "learning_rate = 0.001\n",
        "no_classes = 3\n",
        "validation_split = 0.2\n",
        "verbosity = 1\n",
        "sample_shape = (79,95,68,1)\n",
        "\n",
        "# Create the model --> accuracy del 60% en validación (parece que existe alguna información que aprender)\n",
        "# model = Sequential()\n",
        "# model.add(Conv3D(32, kernel_size=(3,3,3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "# model.add(BatchNormalization()) # añadido\n",
        "# model.add(Conv3D(32, kernel_size=(3,3,3), activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "# model.add(Dropout(0.8)) # añadido\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv3D(32, kernel_size=(3,3,3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "# model.add(BatchNormalization()) # añadido\n",
        "# model.add(Conv3D(32, kernel_size=(3,3,3), activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "# model.add(BatchNormalization()) # añadido\n",
        "# model.add(Conv3D(32, kernel_size=(3,3,3), activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "# model.add(BatchNormalization()) # añadido\n",
        "# model.add(Conv3D(64, kernel_size=(3,3,3), activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dropout(0.2)) # añadido\n",
        "# model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "# # Fit model to data\n",
        "# history = model.fit(X_train, y_train, batch_size=batch_size, \n",
        "#                     epochs=no_epochs, verbose=verbosity, validation_split=validation_split)\n",
        "\n",
        "# # Generate generalization metrics\n",
        "# score = model.evaluate(X_test, y_test, verbose=0)\n",
        "# print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# # Plot history: Categorical crossentropy & Accuracy\n",
        "# # plt.plot(history.history['loss'], label='Categorical crossentropy (training data)')\n",
        "# # plt.plot(history.history['val_loss'], label='Categorical crossentropy (validation data)')\n",
        "# plt.plot(history.history['accuracy'], label='Accuracy (training data)')\n",
        "# plt.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\n",
        "# # plt.title('Model performance for 3D MNIST Keras Conv3D example')\n",
        "# plt.ylabel('Loss value')\n",
        "# plt.xlabel('No. epoch')\n",
        "# plt.legend(loc=\"upper left\")\n",
        "# plt.show()\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14. 14. 22.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nILc6tlEFMT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636d913b-9a92-48a1-b227-60e9603b58f4"
      },
      "source": [
        "\n",
        "# sample_shape = X_train[0].shape\n",
        "\n",
        "# # Basic 3D cnn model\n",
        "# model = Sequential()\n",
        "# model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(79,95,68,1)))\n",
        "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu'))\n",
        "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu'))\n",
        "\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization(center=True, scale=True))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=k.optimizers.Adam(lr=0.001),\n",
        "#               metrics=['accuracy'])\n",
        "# model.summary()\n",
        "# # Fit data to model\n",
        "\n",
        "# history = model.fit(X_train, y_train,\n",
        "#             batch_size=8,\n",
        "#             epochs=40,\n",
        "#             verbose=1,\n",
        "#             validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_24 (Conv3D)           (None, 77, 93, 66, 32)    896       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_13 (MaxPooling (None, 38, 46, 33, 32)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 38, 46, 33, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv3d_25 (Conv3D)           (None, 36, 44, 31, 64)    55360     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_14 (MaxPooling (None, 18, 22, 15, 64)    0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 18, 22, 15, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv3d_26 (Conv3D)           (None, 16, 20, 13, 128)   221312    \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 16, 20, 13, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv3d_27 (Conv3D)           (None, 14, 18, 11, 256)   884992    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_15 (MaxPooling (None, 7, 9, 5, 256)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 7, 9, 5, 256)      1024      \n",
            "_________________________________________________________________\n",
            "conv3d_28 (Conv3D)           (None, 5, 7, 3, 256)      1769728   \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 5, 7, 3, 256)      1024      \n",
            "_________________________________________________________________\n",
            "conv3d_29 (Conv3D)           (None, 3, 5, 1, 256)      1769728   \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 3, 5, 1, 256)      1024      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3840)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 3840)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               1966592   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 6,936,771\n",
            "Trainable params: 6,934,787\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "20/20 [==============================] - 5s 184ms/step - loss: 3.1616 - accuracy: 0.3332 - val_loss: 42.9146 - val_accuracy: 0.2250\n",
            "Epoch 2/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 1.5283 - accuracy: 0.4425 - val_loss: 44.4231 - val_accuracy: 0.2250\n",
            "Epoch 3/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 1.2424 - accuracy: 0.4737 - val_loss: 1.1274 - val_accuracy: 0.4000\n",
            "Epoch 4/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 1.0410 - accuracy: 0.5797 - val_loss: 1.0236 - val_accuracy: 0.5750\n",
            "Epoch 5/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 1.1472 - accuracy: 0.4927 - val_loss: 1.0814 - val_accuracy: 0.4500\n",
            "Epoch 6/40\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 1.0272 - accuracy: 0.5277 - val_loss: 1.1639 - val_accuracy: 0.4500\n",
            "Epoch 7/40\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.9641 - accuracy: 0.5712 - val_loss: 1.1931 - val_accuracy: 0.3250\n",
            "Epoch 8/40\n",
            "20/20 [==============================] - 3s 143ms/step - loss: 0.8394 - accuracy: 0.6313 - val_loss: 1.6128 - val_accuracy: 0.3250\n",
            "Epoch 9/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.6693 - accuracy: 0.7362 - val_loss: 1.5040 - val_accuracy: 0.2250\n",
            "Epoch 10/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.9533 - accuracy: 0.5321 - val_loss: 2.0245 - val_accuracy: 0.2250\n",
            "Epoch 11/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.8020 - accuracy: 0.6330 - val_loss: 0.9872 - val_accuracy: 0.5000\n",
            "Epoch 12/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.8490 - accuracy: 0.6031 - val_loss: 2.0169 - val_accuracy: 0.3250\n",
            "Epoch 13/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.7865 - accuracy: 0.6464 - val_loss: 1.1373 - val_accuracy: 0.3750\n",
            "Epoch 14/40\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.7403 - accuracy: 0.6329 - val_loss: 1.6949 - val_accuracy: 0.4500\n",
            "Epoch 15/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.7149 - accuracy: 0.7461 - val_loss: 5.6674 - val_accuracy: 0.3250\n",
            "Epoch 16/40\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.7523 - accuracy: 0.6753 - val_loss: 2.1989 - val_accuracy: 0.4500\n",
            "Epoch 17/40\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.8119 - accuracy: 0.6946 - val_loss: 1.6414 - val_accuracy: 0.4250\n",
            "Epoch 18/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.8210 - accuracy: 0.6148 - val_loss: 1.1749 - val_accuracy: 0.4250\n",
            "Epoch 19/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.6688 - accuracy: 0.6939 - val_loss: 1.2950 - val_accuracy: 0.4250\n",
            "Epoch 20/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.7005 - accuracy: 0.6787 - val_loss: 31.6361 - val_accuracy: 0.2250\n",
            "Epoch 21/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.7752 - accuracy: 0.7085 - val_loss: 2.3148 - val_accuracy: 0.5250\n",
            "Epoch 22/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.5485 - accuracy: 0.7434 - val_loss: 1.6673 - val_accuracy: 0.5000\n",
            "Epoch 23/40\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.5070 - accuracy: 0.7641 - val_loss: 2.5393 - val_accuracy: 0.4750\n",
            "Epoch 24/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.6389 - accuracy: 0.6597 - val_loss: 2.0125 - val_accuracy: 0.4750\n",
            "Epoch 25/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.6526 - accuracy: 0.7425 - val_loss: 2.8988 - val_accuracy: 0.4500\n",
            "Epoch 26/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.4608 - accuracy: 0.8196 - val_loss: 3.8560 - val_accuracy: 0.4250\n",
            "Epoch 27/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.5912 - accuracy: 0.7502 - val_loss: 2.2117 - val_accuracy: 0.4250\n",
            "Epoch 28/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.4681 - accuracy: 0.8379 - val_loss: 1.6580 - val_accuracy: 0.6000\n",
            "Epoch 29/40\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.6579 - accuracy: 0.8219 - val_loss: 7.3255 - val_accuracy: 0.4000\n",
            "Epoch 30/40\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.5146 - accuracy: 0.7950 - val_loss: 2.7436 - val_accuracy: 0.4000\n",
            "Epoch 31/40\n",
            "20/20 [==============================] - 3s 145ms/step - loss: 0.2838 - accuracy: 0.9196 - val_loss: 2.8144 - val_accuracy: 0.5000\n",
            "Epoch 32/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.4465 - accuracy: 0.8335 - val_loss: 60.2685 - val_accuracy: 0.2250\n",
            "Epoch 33/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.4123 - accuracy: 0.8880 - val_loss: 22.0287 - val_accuracy: 0.2500\n",
            "Epoch 34/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.3398 - accuracy: 0.8469 - val_loss: 11.0347 - val_accuracy: 0.4250\n",
            "Epoch 35/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.3571 - accuracy: 0.8866 - val_loss: 8.4517 - val_accuracy: 0.4250\n",
            "Epoch 36/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.2179 - accuracy: 0.9365 - val_loss: 6.1153 - val_accuracy: 0.3750\n",
            "Epoch 37/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.5548 - accuracy: 0.7896 - val_loss: 12.7417 - val_accuracy: 0.5250\n",
            "Epoch 38/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.7117 - accuracy: 0.8212 - val_loss: 84.1058 - val_accuracy: 0.4250\n",
            "Epoch 39/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.5715 - accuracy: 0.8072 - val_loss: 70.6280 - val_accuracy: 0.3000\n",
            "Epoch 40/40\n",
            "20/20 [==============================] - 3s 144ms/step - loss: 0.3808 - accuracy: 0.9146 - val_loss: 63.2866 - val_accuracy: 0.3000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}