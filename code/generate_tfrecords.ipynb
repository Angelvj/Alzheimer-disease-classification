{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_tfrecords.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNgQHwEdDqhaGp0mflUqViQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelvj/Alzheimer-disease-classification/blob/main/code/generate_tfrecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HClHCALcqKm-"
      },
      "source": [
        "import numpy as np, os, shutil\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkD1Ol2Y3On5",
        "outputId": "f6d3beee-56d8-45bf-dbc7-9a860b797600"
      },
      "source": [
        "if os.path.exists('cloned_repo'):\n",
        "    shutil.rmtree('cloned_repo')\n",
        "    \n",
        "!git clone -l -s https://github.com/Angelvj/TFG.git cloned_repo\n",
        "\n",
        "# Imports from my github repo\n",
        "from cloned_repo.code.image_reading import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned_repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 271, done.\u001b[K\n",
            "remote: Counting objects: 100% (271/271), done.\u001b[K\n",
            "remote: Compressing objects: 100% (215/215), done.\u001b[K\n",
            "remote: Total 271 (delta 94), reused 61 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (271/271), 3.07 MiB | 17.58 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFSbmBE2lIT0"
      },
      "source": [
        "Most of the following code comes from TensorFlow's documentation: [here](https://www.tensorflow.org/tutorials/load_data/tfrecord?hl=en#data_types_for_tftrainexample)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_ekMFklBCC"
      },
      "source": [
        "# The following functions convert a value to a type compatible\n",
        "# with tf.train.Example\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _float_list_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double list\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _int64_list_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint list\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "def serialize_example(image, shape, name, label):\n",
        "    \"\"\"\n",
        "    Creates a tf.train.Example message ready to be written to a file.\n",
        "    \"\"\"\n",
        "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
        "    # data type.\n",
        "    feature = {\n",
        "        'image': _float_list_feature(image),\n",
        "        'shape': _int64_list_feature(shape),\n",
        "        'name': _bytes_feature(name), #TODO: not needed\n",
        "        'label': _int64_feature(label)\n",
        "    }\n",
        "    # Create a Features message using tf.train.Example.\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    return example_proto.SerializeToString()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_9M5vyf4dBj"
      },
      "source": [
        "def generate_tfrecords(img_paths, img_labels, tfrecords_dir, tfrecords_metadata, num_folds=15, \n",
        "                       num_samples=None, stratify=True, shuffle=True, create_folders=True):\n",
        "    \"\"\"Given path to images and corresponding labels, creates num_folds tfrecords containing the images, \n",
        "    or tfrecords containing num_samples each.\"\"\"\n",
        "    \n",
        "    if create_folders and not os.path.exists(tfrecords_dir):\n",
        "        os.makedirs(tfrecords_dir)\n",
        "    \n",
        "    if num_samples is not None:\n",
        "        num_folds = math.ceil(len(img_paths)/num_samples)\n",
        "        \n",
        "    with open(tfrecords_metadata, 'w', encoding='UTF8', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        row = ['tfrecord_name', 'total_samples']\n",
        "        for c in CLASSES:\n",
        "            row.append(c)\n",
        "        writer.writerow(row)\n",
        "\n",
        "    f = open(tfrecords_metadata, 'a', encoding='UTF8', newline='')\n",
        "    csv_writer = csv.writer(f)\n",
        "\n",
        "    if stratify:\n",
        "        kfold = StratifiedKFold(n_splits=num_folds, shuffle=shuffle)\n",
        "    else:\n",
        "        kfold = KFold(n_splits=num_folds, shuffle=shuffle)\n",
        "    \n",
        "    for n, (_, indices) in enumerate(kfold.split(img_paths, img_labels)):\n",
        "        tfrecord_name = f'tfrecord_{n}.tfrec' if create_folders else f'{tfrecords_dir}{n}-{len(indices)}.tfrec'\n",
        "        num_samples = str(len(indices))\n",
        "        unique, counts = np.unique(img_labels[indices], return_counts=True)\n",
        "        per_class_count = np.zeros(len(CLASSES), dtype=np.int64)\n",
        "        per_class_count[unique] = counts\n",
        "        per_class_count = list(per_class_count.astype(str))\n",
        "        row = [tfrecord_name] + [num_samples] + per_class_count\n",
        "        csv_writer.writerow(row)\n",
        "        \n",
        "        aux = os.path.join(tfrecords_dir, tfrecord_name) if create_folders else tfrecord_name\n",
        "        \n",
        "        with tf.io.TFRecordWriter(aux) as writer:\n",
        "            for index in indices:\n",
        "                path = img_paths[index]\n",
        "                img = np.nan_to_num(load_image(path), copy=False)\n",
        "                img_name = str.encode(path.split('/')[-1])\n",
        "                example = serialize_example(img.ravel(), img.shape, img_name, label)\n",
        "                writer.write(example)\n",
        "    f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2gdz8zd-XT9"
      },
      "source": [
        "def unison_shuffled(a, b):\n",
        "    \"\"\" shuffle two ndarrays of same shape, in the same way \"\"\"\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "def stratified_train_test_split(y, test_size = 0.2):\n",
        "    \"\"\" \n",
        "    Given the labels of a dataset, split it into train and test sets, maintaining\n",
        "    proportion of each class (return indices, not data).\n",
        "    \"\"\"\n",
        "    if not isinstance(y, np.ndarray):\n",
        "        y = np.array(y)\n",
        "\n",
        "    train_idx = np.zeros((0,), np.int16)\n",
        "    test_idx = np.zeros((0,), np.int16)\n",
        "\n",
        "    for label in np.unique(y):\n",
        "        idx = np.where(y==label)[0]\n",
        "        test_idx_aux = np.random.choice(idx, int(idx.shape[0]*test_size), replace=False)\n",
        "        test_idx = np.concatenate((test_idx, test_idx_aux))\n",
        "        train_idx = np.concatenate((train_idx, np.setdiff1d(idx, test_idx_aux, assume_unique=True)))\n",
        "\n",
        "    return train_idx, test_idx"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12UBtsAWqxp5",
        "outputId": "e2de46e0-bd29-42be-f511-0eeff326dc21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "COLAB = True\n",
        "\n",
        "# ============== Path to data ==============\n",
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Root data folder\n",
        "    ROOT = '/content/drive/My Drive/Machine learning/data'\n",
        "    # Path to brain images\n",
        "else:\n",
        "    ROOT = '/kaggle/input'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgFkwkBjq0Tu"
      },
      "source": [
        "# =========== Path to images folder ===========\n",
        "preprocessed = ROOT + '/preprocessed-nii'\n",
        "\n",
        "# Classes in the dataset\n",
        "CLASSES = ['NOR', 'AD', 'MCI']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMzppPG5q3t4"
      },
      "source": [
        "# Path to PET images\n",
        "pet_paths = np.empty((0,), dtype=str)\n",
        "pet_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "for label, c in enumerate(CLASSES):\n",
        "    aux = os.path.join(preprocessed, c, 'PET')\n",
        "    for f in os.listdir(aux):\n",
        "        if f.endswith('.nii'):\n",
        "            path = os.path.join(aux, f)\n",
        "            pet_paths = np.concatenate((pet_paths, path), axis=None)\n",
        "            pet_labels = np.concatenate((pet_labels, label), axis=None)\n",
        "\n",
        "# Path to MRI, grey matter images\n",
        "mri_grey_paths = np.empty((0,), dtype=str)\n",
        "mri_grey_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "for label, c in enumerate(CLASSES):\n",
        "    aux = os.path.join(preprocessed, c, 'MRI/grey')\n",
        "    for f in os.listdir(aux):\n",
        "        if f.endswith('.nii'):\n",
        "            path = os.path.join(aux, f)\n",
        "            mri_grey_paths = np.concatenate((mri_grey_paths, path), axis=None)\n",
        "            mri_grey_labels = np.concatenate((mri_grey_labels, label), axis=None)\n",
        "\n",
        "# Path to MRI, white matter images\n",
        "mri_white_paths = np.empty((0,), dtype=str)\n",
        "mri_white_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "for label, c in enumerate(CLASSES):\n",
        "    aux = os.path.join(preprocessed, c, 'MRI/white')\n",
        "    for f in os.listdir(aux):\n",
        "        if f.endswith('.nii'):\n",
        "            path = os.path.join(aux, f)\n",
        "            mri_white_paths = np.concatenate((mri_white_paths, path), axis=None)\n",
        "            mri_white_labels = np.concatenate((mri_white_labels, label), axis=None)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWsrMYYqrBnM"
      },
      "source": [
        "# Put all images in the same order so that each position on the three datasets correspond to the same patient\n",
        "# This is not useful by now, it will be useful in a future ensemble model with MRI and PET.\n",
        "idx = np.argsort(pet_paths)\n",
        "pet_paths, pet_labels = pet_paths[idx], pet_labels[idx]\n",
        "\n",
        "idx = np.argsort(mri_grey_paths)\n",
        "mri_grey_paths, mri_grey_labels = mri_grey_paths[idx], mri_grey_labels[idx]\n",
        "\n",
        "idx = np.argsort(mri_white_paths)\n",
        "mri_white_paths, mri_white_labels = mri_white_paths[idx], mri_white_labels[idx]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjw1gBmDrDKq"
      },
      "source": [
        "# Generating datasets with tfrecords\n",
        "train_idx, test_idx = stratified_train_test_split(pet_labels, test_size=0.2)\n",
        "\n",
        "dir = ROOT + '/preprocessed-tfrecords-20skf/'\n",
        "\n",
        "generate_tfrecords(pet_paths[train_idx], pet_labels[train_idx], dir + 'PET/train', \n",
        "                   dir + 'PET/train/tfrec_metadata.csv', num_folds=20, stratify=True, \n",
        "                   shuffle=True, create_folders=True)\n",
        "generate_tfrecords(pet_paths[test_idx], pet_labels[test_idx], dir + 'PET/test', \n",
        "                   dir + 'PET/test/tfrec_metadata.csv', num_folds=16, stratify=False, \n",
        "                   shuffle=False, create_folders=True)\n",
        "\n",
        "generate_tfrecords(mri_grey_paths[train_idx], mri_grey_labels[train_idx], dir + 'MRI/white/train', \n",
        "                   dir + 'MRI/white/train/tfrec_metadata.csv',num_folds=20, stratify=True, \n",
        "                   shuffle=True, create_folders=True)\n",
        "generate_tfrecords(mri_grey_paths[test_idx], mri_grey_labels[test_idx], dir + 'MRI/white/test', \n",
        "                   dir + 'MRI/white/test/tfrec_metadata.csv', num_folds=16, stratify=False, \n",
        "                   shuffle=False, create_folders=True)\n",
        "\n",
        "generate_tfrecords(mri_white_paths[train_idx], mri_white_labels[train_idx], dir + 'MRI/grey/train', \n",
        "                   dir +'MRI/grey/train/tfrec_metadata.csv',num_folds=20, stratify=True, \n",
        "                   shuffle=True, create_folders=True)\n",
        "generate_tfrecords(mri_white_paths[test_idx], mri_white_labels[test_idx], dir + 'MRI/grey/test', \n",
        "                   dir + 'MRI/grey/test/tfrec_metadata.csv',num_folds=16, stratify=False, \n",
        "                   shuffle=False, create_folders=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hfgX01LrF__"
      },
      "source": [
        "# shutil.rmtree('PET')\n",
        "# shutil.rmtree('MRI')\n",
        "# shutil.rmtree('cloned_repo')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}