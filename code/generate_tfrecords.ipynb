{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_tfrecords.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNBa+4rbkYSgqs9mawmxV3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelvj/Alzheimer-disease-classification/blob/main/code/generate_tfrecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjtbzMZY8o8b"
      },
      "source": [
        "This notebook has the function of converting the original dataset in tfrecords (better performance on i/o operations and other advantages). We will execute this notebook on Google Colab because we can organize the outputs into folders."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSCeWput8jwe"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaQd0Oxy8hIm"
      },
      "source": [
        "# Colab only\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HClHCALcqKm-"
      },
      "source": [
        "import sys\n",
        "import numpy as np, os, shutil, math\n",
        "import tensorflow as tf, csv\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "import nibabel as nib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkD1Ol2Y3On5"
      },
      "source": [
        "def load_image(path):    \n",
        "\n",
        "    img = nib.load(path)\n",
        "    img = np.asarray(img.dataobj, dtype=np.float32)\n",
        "    img = np.expand_dims(img, axis=3) # Add axis for channel\n",
        "    return img\n",
        "\n",
        "def standarize(X):\n",
        "\n",
        "    mean = np.mean(X)\n",
        "    std = np.std(X)\n",
        "    \n",
        "    if std > 0:\n",
        "        X -= mean\n",
        "        X /= std\n",
        "    else:\n",
        "        X *= 0\n",
        "\n",
        "def max_intensity_normalization(X, proportion):\n",
        "\n",
        "    n_max_values = int(np.prod(X.shape, axis=0) * proportion)\n",
        "    n_max_idx = np.unravel_index((X).argsort(axis=None)[-n_max_values:], X.shape)\n",
        "    mean = np.mean(X[n_max_idx])\n",
        "    X /= mean\n",
        "\n",
        "def preprocess_image(X, steps, arguments):\n",
        "\n",
        "    for f, args in zip(steps, arguments):\n",
        "        if args is None:\n",
        "            f(X)\n",
        "        else:\n",
        "            f(X, *args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmorIHDy9B9b"
      },
      "source": [
        "# Generate Tfrecords dataset from images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_ekMFklBCC"
      },
      "source": [
        "# We can store three types of data in a TFRecord: bytestring, integer and floats. \n",
        "# They are always stored as lists, a single data element will be a list of size 1\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "\n",
        "def _float_feature(list_of_floats): # float32\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
        "\n",
        "def _int_feature(list_of_ints): # int64\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
        "\n",
        "def to_tfrecord(image, label):\n",
        "    \n",
        "    one_hot_label = np.eye(3, dtype=np.float32)[label]\n",
        "        \n",
        "    feature = {\n",
        "        'image': _float_feature(image),\n",
        "        'one_hot_label': _float_feature(one_hot_label.tolist())\n",
        "    }\n",
        "    \n",
        "    # Create a Features message\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_9M5vyf4dBj"
      },
      "source": [
        "def generate_tfrecords(filenames, labels, dir, tfrec_name, preprocess_steps=None, \n",
        "                       prepr_args=None, num_folds=15, stratify=True, shuffle=True, \n",
        "                       random_state=None, make_summary=True):\n",
        "    \"\"\"Given path to images and corresponding labels, creates num_folds tfrecords \n",
        "    containing the images\"\"\"\n",
        "    \n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "    \n",
        "    if make_summary:\n",
        "        summary_filename = os.path.join(dir, tfrec_name,)\n",
        "        summary_filename += '_summary.csv'\n",
        "        with open(summary_filename, 'w', encoding='UTF8', newline='') as f:\n",
        "            csv_writer = csv.writer(f)\n",
        "            header = ['tfrec_id', '#samples']\n",
        "            header += [c for c in CLASSES]\n",
        "            csv_writer.writerow(header)\n",
        "\n",
        "        f = open(summary_filename, 'a', encoding='UTF8', newline='')\n",
        "        csv_writer = csv.writer(f)\n",
        "\n",
        "    if stratify:\n",
        "        kfold = StratifiedKFold(num_folds, shuffle, random_state)\n",
        "    else:\n",
        "        kfold = KFold(num_folds, shuffle, random_state)\n",
        "    \n",
        "    for n, (_, indices) in enumerate(kfold.split(filenames, labels)):\n",
        "                \n",
        "        name = f'{tfrec_name}_{n}-{len(indices)}.tfrec'\n",
        "\n",
        "        if make_summary:\n",
        "            num_samples = str(len(indices))\n",
        "            classes, count = np.unique(labels[indices], return_counts=True)\n",
        "            class_counts = np.zeros(len(CLASSES), dtype=np.int64)\n",
        "            class_counts[classes] = count\n",
        "            row = [name] + [num_samples] + list(class_counts.astype(str))\n",
        "            csv_writer.writerow(row)\n",
        "        \n",
        "        with tf.io.TFRecordWriter(os.path.join(dir, name)) as writer:\n",
        "\n",
        "            for index in indices:\n",
        "                filename = filenames[index]\n",
        "                label = labels[index]\n",
        "                img = np.nan_to_num(load_image(filename), copy=False)\n",
        "                if preprocess_steps != None:\n",
        "                    preprocess_image(img, preprocess_steps, prepr_args)\n",
        "                example = to_tfrecord(img.ravel(), label)\n",
        "                writer.write(example.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2gdz8zd-XT9"
      },
      "source": [
        "# Not used\n",
        "# def stratified_train_test_split(y, test_size = 0.2):\n",
        "#     \"\"\" \n",
        "#     Given the labels of a dataset, split it into train and test sets, maintaining\n",
        "#     proportion of each class (return indices, not data).\n",
        "#     \"\"\"\n",
        "#     if not isinstance(y, np.ndarray):\n",
        "#         y = np.array(y)\n",
        "\n",
        "#     train_idx = np.zeros((0,), np.int64)\n",
        "#     test_idx = np.zeros((0,), np.int64)\n",
        "\n",
        "#     for label in np.unique(y):\n",
        "#         idx = np.where(y==label)[0]\n",
        "#         test_idx_aux = np.random.choice(idx, int(idx.shape[0]*test_size), replace=False)\n",
        "#         test_idx = np.concatenate((test_idx, test_idx_aux))\n",
        "#         train_idx = np.concatenate((train_idx, np.setdiff1d(idx, test_idx_aux, assume_unique=True)))\n",
        "\n",
        "#     return train_idx, test_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12UBtsAWqxp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29cbe22-b9ff-4fb5-8235-c52b3c8ebb4f"
      },
      "source": [
        "# Classes in the dataset. Note: the position in the vector sets the class label\n",
        "CLASSES = ['NOR', 'AD', 'MCI']\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = '/content/drive/My Drive/data/'\n",
        "\n",
        "SEED = 27"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogg3zU41N4Ah"
      },
      "source": [
        "# 1. AD - PET images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GABzDdYmR0lv"
      },
      "source": [
        "## 1.1 : Spatially normalized (elastic deformations) PET images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3eZa9WTKNy"
      },
      "source": [
        "DS = 'ad-preprocessed'\n",
        "DS_PATH =  DATA_PATH + DS\n",
        "\n",
        "# Path to images\n",
        "pet_paths = np.empty((0,), dtype=str)\n",
        "pet_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "for label, c in enumerate(CLASSES):\n",
        "    pattern = os.path.join(DS_PATH, c, 'PET') + '/*.nii'\n",
        "    pet_paths = np.concatenate((pet_paths, np.array(tf.io.gfile.glob(pattern))))\n",
        "    pet_labels = np.concatenate((pet_labels, np.full(len(pet_paths) - len(pet_labels), label, dtype=np.int64)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pet_paths, pet_labels,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = SEED,\n",
        "                                                    stratify = pet_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-PBlxKySh3D"
      },
      "source": [
        "### 1.1.1: Non intensity normalized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "BF-lws3GSzo6"
      },
      "source": [
        "OUT_DS = 'tfrec-pet-spatialnorm-elastic'\n",
        "OUT_PATH = DATA_PATH + OUT_DS\n",
        "\n",
        "generate_tfrecords(X_train, y_train, OUT_PATH + '/train', 'train',\n",
        "                   num_folds=len(X_train), stratify=False, shuffle=False, random_state=None)\n",
        "\n",
        "generate_tfrecords(X_test, y_test, OUT_PATH + '/test', 'test', num_folds=len(X_test), \n",
        "                   stratify=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFL_834KSosA"
      },
      "source": [
        "### 1.1.2: Max-intensity normalized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfYMtLkqS_MI"
      },
      "source": [
        "OUT_DS = 'tfrec-PET-spatialnorm-elastic-maxintensitynorm'\n",
        "OUT_PATH = DATA_PATH + OUT_DS\n",
        "\n",
        "preprocess_steps = [max_intensity_normalization]\n",
        "preprocess_args = [(0.01,)]\n",
        "\n",
        "generate_tfrecords(X_train, y_train, OUT_PATH + '/train', 'train', preprocess_steps,\n",
        "                   preprocess_args, len(X_train), False, False)\n",
        "\n",
        "generate_tfrecords(X_test, y_test, OUT_PATH + '/test', 'test', preprocess_steps, \n",
        "                   preprocess_args, len(X_test), stratify=False, shuffle=False,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiMyxU1Cocp"
      },
      "source": [
        "### 1.1.3 Standarized (zero mean unit variance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jY-DiQvCwaH"
      },
      "source": [
        "OUT_DS = 'tfrec-PET-spatialnorm-elastic-standarized'\n",
        "OUT_PATH = DATA_PATH + OUT_DS\n",
        "\n",
        "preprocess_steps = [standarize]\n",
        "preprocess_args = [None]\n",
        "\n",
        "generate_tfrecords(X_train, y_train, OUT_PATH + '/train', 'train', preprocess_steps,\n",
        "                   preprocess_args, len(X_train), False, False)\n",
        "\n",
        "generate_tfrecords(X_test, y_test, OUT_PATH + '/test', 'test', preprocess_steps,\n",
        "                   preprocess_args, len(X_test), stratify=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC9BhicwLgmY"
      },
      "source": [
        "### 1.1.4 Max-intensity normalized and standarized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFlK04vuLnvJ"
      },
      "source": [
        "OUT_DS = 'tfrec-PET-spatialnorm-elastic-maxintensitynorm-standarized'\n",
        "OUT_PATH = DATA_PATH + OUT_DS\n",
        "\n",
        "preprocess_steps = [max_intensity_normalization, standarize]\n",
        "preprocess_args = [(0.01,), None]\n",
        "\n",
        "generate_tfrecords(X_train, y_train, OUT_PATH + '/train', 'train', preprocess_steps, \n",
        "                   preprocess_args, len(X_train), False, False)\n",
        "\n",
        "generate_tfrecords(X_test, y_test, OUT_PATH + '/test', 'test', preprocess_steps, \n",
        "                   preprocess_args, len(X_test), stratify=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7ZZ4OhpSNmI"
      },
      "source": [
        "## 1.2: Spatially normalized (non-elastic deformations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxM66bzRpyme"
      },
      "source": [
        "### 1.2.1 Non intensity normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S09GBO_Lq966"
      },
      "source": [
        "OUT_DS = 'tfrec-pet-spatialnorm-rigid'\n",
        "OUT_PATH = DATA_PATH + OUT_DS\n",
        "\n",
        "generate_tfrecords(X_train, y_train, OUT_PATH + '/train', 'train',\n",
        "                   num_folds=len(X_train), stratify=False, shuffle=False, random_state=None)\n",
        "\n",
        "generate_tfrecords(X_test, y_test, OUT_PATH + '/test', 'test', num_folds=len(X_test), \n",
        "                   stratify=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXfnwWRXpyOJ"
      },
      "source": [
        "### 1.2.2 Standarized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj5TMkgTrB2I"
      },
      "source": [
        "OUT_DS = 'tfrec-pet-spatialnorm-rigid-standarized'\n",
        "OUT_PATH = DATA_PATH + OUT_DS\n",
        "\n",
        "preprocess_steps = [standarize]\n",
        "preprocess_args = [None]\n",
        "\n",
        "generate_tfrecords(X_train, y_train, OUT_PATH + '/train', 'train', preprocess_steps,\n",
        "                   preprocess_args, len(X_train), False, False)\n",
        "\n",
        "generate_tfrecords(X_test, y_test, OUT_PATH + '/test', 'test', preprocess_steps, \n",
        "                   preprocess_args, len(X_test), stratify=False, shuffle=False,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Z-r3TXqBPW"
      },
      "source": [
        "### 1.2.3 Max intensity normalization & standarized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYwettZCrrw6"
      },
      "source": [
        "OUT_DS = 'tfrec-PET-spatialnorm-rigid-maxintensitynorm-standarized'\n",
        "OUT_PATH = DATA_PATH + OUT_DS\n",
        "\n",
        "preprocess_steps = [max_intensity_normalization, standarize]\n",
        "preprocess_args = [(0.01,), None]\n",
        "\n",
        "generate_tfrecords(X_train, y_train, OUT_PATH + '/train', 'train', preprocess_steps, \n",
        "                   preprocess_args, len(X_train), False, False)\n",
        "\n",
        "generate_tfrecords(X_test, y_test, OUT_PATH + '/test', 'test', preprocess_steps, \n",
        "                   preprocess_args, len(X_test), stratify=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svDeRULEQtxA"
      },
      "source": [
        "# 2. AD - MRI Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMzppPG5q3t4"
      },
      "source": [
        "# # Path to MRI, grey matter images\n",
        "# mri_grey_paths = np.empty((0,), dtype=str)\n",
        "# mri_grey_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "# for label, c in enumerate(CLASSES):\n",
        "#     pattern = os.path.join(DS_PATH, c, 'MRI/grey') + '/*.nii'\n",
        "#     mri_grey_paths = np.concatenate((mri_grey_paths, np.array(tf.io.gfile.glob(pattern))))\n",
        "#     mri_grey_labels = np.concatenate((mri_grey_labels, np.full(len(mri_grey_paths) - len(mri_grey_labels), label, dtype=np.int64)))\n",
        "    \n",
        "# # Path to MRI, white matter images\n",
        "# mri_white_paths = np.empty((0,), dtype=str)\n",
        "# mri_white_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "# for label, c in enumerate(CLASSES):\n",
        "#     pattern = os.path.join(DS_PATH, c, 'MRI/white') + '/*.nii'\n",
        "#     mri_white_paths = np.concatenate((mri_white_paths, np.array(tf.io.gfile.glob(pattern))))\n",
        "#     mri_white_labels = np.concatenate((mri_white_labels, np.full(len(mri_white_paths) - len(mri_white_labels), label, dtype=np.int64)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWsrMYYqrBnM"
      },
      "source": [
        "# # Put all images in the same order so that each position on the three datasets correspond to the same patient\n",
        "# # This is not useful by now, it will be useful in a future ensemble model with MRI and PET.\n",
        "# idx = np.argsort(pet_paths)\n",
        "# pet_paths, pet_labels = pet_paths[idx], pet_labels[idx]\n",
        "\n",
        "# idx = np.argsort(mri_grey_paths)\n",
        "# mri_grey_paths, mri_grey_labels = mri_grey_paths[idx], mri_grey_labels[idx]\n",
        "\n",
        "# idx = np.argsort(mri_white_paths)\n",
        "# mri_white_paths, mri_white_labels = mri_white_paths[idx], mri_white_labels[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjw1gBmDrDKq"
      },
      "source": [
        "# # Generating datasets with tfrecords\n",
        "# train_idx, test_idx = stratified_train_test_split(pet_labels, test_size=0.2)\n",
        "\n",
        "# np.random.shuffle(train_idx); np.random.shuffle(test_idx) # Add some randomness\n",
        "\n",
        "# generate_tfrecords(pet_paths[train_idx], pet_labels[train_idx], OUT_PATH + '/PET/train', \n",
        "#                    OUT_PATH + '/PET/train/tfrec_metadata.csv', num_folds=20, stratify=True, \n",
        "#                    shuffle=True, create_folders=True)\n",
        "# generate_tfrecords(pet_paths[test_idx], pet_labels[test_idx], OUT_PATH + '/PET/test', \n",
        "#                    OUT_PATH + '/PET/test/tfrec_metadata.csv', num_folds=16, stratify=False, \n",
        "#                    shuffle=False, create_folders=True)\n",
        "\n",
        "# generate_tfrecords(mri_grey_paths[train_idx], mri_grey_labels[train_idx], OUT_PATH + '/MRI/white/train', \n",
        "#                    OUT_PATH + '/MRI/white/train/tfrec_metadata.csv',num_folds=20, stratify=True, \n",
        "#                    shuffle=True, create_folders=True)\n",
        "# generate_tfrecords(mri_grey_paths[test_idx], mri_grey_labels[test_idx], OUT_PATH + '/MRI/white/test', \n",
        "#                    OUT_PATH + '/MRI/white/test/tfrec_metadata.csv', num_folds=16, stratify=False, \n",
        "#                    shuffle=False, create_folders=True)\n",
        "\n",
        "# generate_tfrecords(mri_white_paths[train_idx], mri_white_labels[train_idx], OUT_PATH + '/MRI/grey/train', \n",
        "#                    OUT_PATH +'/MRI/grey/train/tfrec_metadata.csv',num_folds=20, stratify=True, \n",
        "#                    shuffle=True, create_folders=True)\n",
        "# generate_tfrecords(mri_white_paths[test_idx], mri_white_labels[test_idx], OUT_PATH + '/MRI/grey/test', \n",
        "#                    OUT_PATH + '/MRI/grey/test/tfrec_metadata.csv',num_folds=16, stratify=False, \n",
        "#                    shuffle=False, create_folders=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}