{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_tfrecords.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNy65A3CYGArOZEzHWWwsUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelvj/TFG/blob/main/code/generate_tfrecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkD1Ol2Y3On5",
        "outputId": "d9f22851-2270-46ef-b8d2-a2772325e95c"
      },
      "source": [
        "# Clone my repo.\n",
        "!git clone -l -s https://github.com/Angelvj/TFG.git cloned-repo\n",
        "# Change directory into code dir\n",
        "%cd cloned-repo/code\n",
        "# List repo contents\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Counting objects: 100% (256/256), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 256 (delta 87), reused 61 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (256/256), 3.07 MiB | 17.35 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "/content/cloned-repo/code\n",
            "generate_tfrecords.ipynb  image_reading.py  main.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtshsV--k8C0"
      },
      "source": [
        "import numpy as np, os\n",
        "import tensorflow as tf\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import csv\n",
        "from image_reading import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFSbmBE2lIT0"
      },
      "source": [
        "Most of the following code comes from TensorFlow's documentation: [here](https://www.tensorflow.org/tutorials/load_data/tfrecord?hl=en#data_types_for_tftrainexample)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_ekMFklBCC"
      },
      "source": [
        "# The following functions convert a value to a type compatible\n",
        "# with tf.train.Example\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _float_list_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double list\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint list\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "def serialize_example(image, shape, name, label):\n",
        "    \"\"\"\n",
        "    Creates a tf.train.Example message ready to be written to a file.\n",
        "    \"\"\"\n",
        "    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
        "    # data type.\n",
        "    feature = {\n",
        "        'image': _float_list_feature(image),\n",
        "        'shape': _int64_list_feature(shape),\n",
        "        'name': _bytes_feature(name), #TODO: not needed\n",
        "        'label': _int64_feature(label)\n",
        "    }\n",
        "    # Create a Features message using tf.train.Example.\n",
        "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    return example_proto.SerializeToString()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeH2Q9OT8dzC"
      },
      "source": [
        "# Functions for generating TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_9M5vyf4dBj"
      },
      "source": [
        "def generate_labeled_tfrecords(img_paths, img_labels, tfrecords_dir, tfrecords_labels, num_groups=10):\n",
        "    \"\"\"\n",
        "    For each class, create num_groups tfrecords. The label of the images contained\n",
        "    on each tfrecord is saved into de file tfrecords_labels.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(tfrecords_dir):\n",
        "        os.makedirs(tfrecords_dir)\n",
        "\n",
        "    with open(tfrecords_labels, 'w', encoding='UTF8', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['tfrecord_name', 'label'])\n",
        "\n",
        "    f = open(tfrecords_labels, 'a', encoding='UTF8', newline='')\n",
        "    csv_writer = csv.writer(f)\n",
        "\n",
        "    for label in np.unique(img_labels):\n",
        "        \n",
        "        imgs_current_label = img_paths[img_labels == label]\n",
        "        skfold = StratifiedKFold(n_splits = num_groups) # TODO: stratified not needed\n",
        "        groups_generator = skfold.split(imgs_current_label, np.full(imgs_current_label.shape, label))\n",
        "        \n",
        "        for n, (_, indices) in enumerate(groups_generator):\n",
        "        \n",
        "            tfrecord_name = f'tfrecord_l{label}_{n}.tfrec'\n",
        "            csv_writer.writerow([tfrecord_name, str(label)])\n",
        "            \n",
        "            with tf.io.TFRecordWriter(os.path.join(tfrecords_dir, tfrecord_name)) as writer:\n",
        "\n",
        "                for index in indices:\n",
        "                    path = imgs_current_label[index]\n",
        "                    img = np.nan_to_num(load_image(path), copy=False)\n",
        "                    img_name = str.encode(path.split('/')[-1])\n",
        "                    example = serialize_example(img.ravel(), img.shape, img_name, label)\n",
        "                    writer.write(example)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def generate_tfrecords(img_paths, img_labels, tfrecords_dir, tfrecords_labels = None, num_samples=10):\n",
        "\n",
        "    \"\"\"\n",
        "    Create tfrecords containing num_samples imgs each. If a file for saving tfrecord\n",
        "    labels is passed, each tfrecord will contain only one image, and label will be\n",
        "    saved into the file.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(tfrecords_dir):\n",
        "        os.makedirs(tfrecords_dir)\n",
        "    \n",
        "    if tfrecords_labels is not None:\n",
        "        num_samples = 1\n",
        "\n",
        "        with open(tfrecords_labels, 'w', encoding='UTF8', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(['tfrecord_name', 'label'])\n",
        "\n",
        "        f = open(tfrecords_labels, 'a', encoding='UTF8', newline='')\n",
        "        csv_writer = csv.writer(f)\n",
        "\n",
        "    num_tfrecords = img_paths.shape[0] // num_samples\n",
        "\n",
        "    if img_paths.shape[0] % num_samples:\n",
        "        num_tfrecords += 1\n",
        "\n",
        "    for j in range(num_tfrecords):\n",
        "        \n",
        "        tfrec_name = f'tfrecord_{j}.tfrec'\n",
        "        with tf.io.TFRecordWriter(os.path.join(tfrecords_dir, tfrec_name)) as writer:\n",
        "\n",
        "            for k in range(min(num_samples, len(img_paths) - j*num_samples)):\n",
        "\n",
        "                path = img_paths[num_samples*j + k]\n",
        "                label = img_labels[num_samples*j + k]\n",
        "                img = np.nan_to_num(load_image(path), copy=False)\n",
        "                img_name = str.encode(path.split('/')[-1])\n",
        "                example = serialize_example(img.ravel(), img.shape, img_name, label)\n",
        "                writer.write(example)\n",
        "\n",
        "                if num_samples == 1:\n",
        "                    csv_writer.writerow([tfrec_name, label])\n",
        "    f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYdI7PQKN7n9"
      },
      "source": [
        "# Functions for splitting into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2gdz8zd-XT9"
      },
      "source": [
        "def unison_shuffled(a, b):\n",
        "    \"\"\" shuffle two ndarrays of same shape, in the same way \"\"\"\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "def stratified_train_test_split(y, test_size = 0.2, shuffle = True):\n",
        "    \"\"\" \n",
        "    Given the labels of a dataset, split it into train and test sets, maintaining\n",
        "    proportion of each class (return indices, not data).\n",
        "    \"\"\"\n",
        "    if not isinstance(y, np.ndarray):\n",
        "        y = np.array(y)\n",
        "\n",
        "    initial_idx = np.arange(y.shape[0])\n",
        "\n",
        "    if shuffle:\n",
        "        y, initial_idx = unison_shuffled(y, initial_idx)\n",
        "\n",
        "    train_idx = np.zeros((0,), np.int16)\n",
        "    test_idx = np.zeros((0,), np.int16)\n",
        "\n",
        "    for label in np.unique(y):\n",
        "        idx = np.where(y==label)[0]\n",
        "        test_idx_aux = np.random.choice(idx, int(idx.shape[0]*test_size), replace=False)\n",
        "        test_idx = np.concatenate((test_idx, test_idx_aux))\n",
        "        train_idx = np.concatenate((train_idx, np.setdiff1d(idx, test_idx_aux, assume_unique=True)))\n",
        "\n",
        "    return initial_idx[train_idx], initial_idx[test_idx]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QptQaiMlh8rI"
      },
      "source": [
        "# Initial variables about data organization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_NExwhRsfL9",
        "outputId": "a6c910b2-ab1c-42c5-ecd2-32260ed66bac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============== PATH TO IMAGES ==============\n",
        "\n",
        "# Root data folder\n",
        "ROOT = '/content/drive/My Drive/Machine learning/data'\n",
        "\n",
        "# Path to brain images\n",
        "BRAIN = ROOT + '/alzheimer_pet&mri'\n",
        "BRAIN_PREPROCESSED = BRAIN + '/preprocessed'\n",
        "BRAIN_RAW = BRAIN + '/raw'\n",
        "\n",
        "# Paths brain images modalities\n",
        "PET_PREPROCESSED = BRAIN_PREPROCESSED + '/PET'\n",
        "MRI_PREPROCESSED= BRAIN_PREPROCESSED + '/MRI'\n",
        "PET_RAW = BRAIN_RAW + '/PET'\n",
        "MRI_RAW = BRAIN_RAW + '/MRI'\n",
        "\n",
        "# Preprocessed MRI subtypes (divided into grey and white matter)\n",
        "MRI_MATTER = ['GREY', 'WHITE']\n",
        "\n",
        "# Class subfolders and labels for each one\n",
        "CLASSES = ['ppNOR', 'ppAD', 'ppMCI'] \n",
        "LABELS = {'ppNOR': 0, 'ppAD': 1, 'ppMCI': 2}\n",
        "\n",
        "# ============== PATH TO TFRECORDS ==============\n",
        "\n",
        "PET_PREPROCESSED_TFREC = PET_PREPROCESSED + '/tfrecords'\n",
        "MRI_PREPROCESSED_TFREC = MRI_PREPROCESSED + '/tfrecords'\n",
        "PET_RAW_TFREC = PET_RAW + '/tfrecords'\n",
        "MRI_RAW_TFREC = MRI_RAW + '/tfrecords'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MN2YSUIXU7m"
      },
      "source": [
        "# Read images, split into train and test sets\n",
        "... and create tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGg9Hhh6LyBV"
      },
      "source": [
        "# ================= create PREPROCESED PET tfrecords =================\n",
        "img_paths = np.empty((0,), dtype=str)\n",
        "img_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "for c in CLASSES:\n",
        "    path = os.path.join(PET_PREPROCESSED, c)\n",
        "    label = LABELS[c]\n",
        "    for f in os.listdir(path):\n",
        "        full_path = os.path.join(path, f)\n",
        "        if os.path.isfile(full_path):\n",
        "            img_paths = np.concatenate((img_paths, full_path), axis = None)\n",
        "            img_labels = np.concatenate((img_labels, label), axis = None)\n",
        "\n",
        "ordered_idx = np.argsort(img_paths) # Sort to have the same order of patients in MRI\n",
        "img_paths, img_labels = img_paths[ordered_idx], img_labels[ordered_idx]\n",
        "\n",
        "# IMPORTANT: we want to make an ensemble classifier with PET and MRI images.\n",
        "# So we have use this partition also for MRI, if not, we would be leaking data.\n",
        "train_idx, test_idx = stratified_train_test_split(img_labels, test_size=0.2)\n",
        "\n",
        "X_train, y_train= img_paths[train_idx], img_labels[train_idx]\n",
        "X_test, y_test = img_paths[test_idx], img_labels[test_idx]\n",
        "\n",
        "# Generate train and test tfrecords\n",
        "generate_tfrecords(X_train, y_train, PET_PREPROCESSED_TFREC + '/train', PET_PREPROCESSED_TFREC + \"/train/tfrecords_labels.csv\")\n",
        "generate_tfrecords(X_test, y_test, PET_PREPROCESSED_TFREC + '/test', PET_PREPROCESSED_TFREC + \"/test/tfrecords_labels.csv\")\n",
        "\n",
        "# ================= create PREPROCESED MRI tfrecords =================\n",
        "for matter in MRI_MATTER:\n",
        "\n",
        "    img_paths = np.empty((0,), dtype=str)\n",
        "    img_labels = np.empty((0,), dtype=np.int64)\n",
        "\n",
        "    for c in CLASSES:\n",
        "        path = os.path.join(MRI_PREPROCESSED, c, matter)\n",
        "        label = LABELS[c]\n",
        "        for f in os.listdir(path):\n",
        "            full_path = os.path.join(path, f)\n",
        "            if os.path.isfile(full_path):\n",
        "                img_paths = np.concatenate((img_paths, full_path), axis = None)\n",
        "                img_labels = np.concatenate((img_labels, label), axis = None)\n",
        "\n",
        "\n",
        "    ordered_idx = np.argsort(img_paths)\n",
        "    img_paths, img_labels = img_paths[ordered_idx], img_labels[ordered_idx]\n",
        "\n",
        "    # Same idx as before\n",
        "    X_train, y_train = img_paths[train_idx], img_labels[train_idx]\n",
        "    X_test, y_test = img_paths[test_idx], img_labels[test_idx]\n",
        "\n",
        "    # Generate train and test tfrecords\n",
        "    generate_tfrecords(X_train, y_train, MRI_PREPROCESSED_TFREC + f'/{matter}/train', MRI_PREPROCESSED_TFREC + f\"/{matter}/train/tfrecords_labels.csv\")\n",
        "    generate_tfrecords(X_test, y_test, MRI_PREPROCESSED_TFREC + f'/{matter}/test', MRI_PREPROCESSED_TFREC + f\"/{matter}/test/tfrecords_labels.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}