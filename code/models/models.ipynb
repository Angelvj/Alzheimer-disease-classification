{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOo1v2xiXlRXyvr3p+dOl9e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelvj/Alzheimer-disease-classification/blob/main/code/models/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6myISJ6OuOp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import six\n",
        "import tensorflow.keras.backend as K\n",
        "from math import ceil\n",
        "from tensorflow.keras.layers import MaxPooling3D, Flatten, Dense, Conv3D, BatchNormalization, Input, Dropout, GlobalAveragePooling3D, add, Activation, concatenate\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZjULrA88_Nt"
      },
      "source": [
        "pet_shape = (79, 95, 68, 1)\n",
        "mri_shape = (121, 145, 121, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMXDXFhKY2XG"
      },
      "source": [
        "# Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ-psCMrY5aL"
      },
      "source": [
        "def change_input_shape(model, new_shape, name=None):\n",
        "    new_shape = [None] + list(new_shape)\n",
        "    new_shape = tuple(new_shape)\n",
        "    # Extract model's configuration\n",
        "    model_config = model.get_config()\n",
        "    # Change config\n",
        "    if name is not None:\n",
        "        input_layer_name = name\n",
        "    else:\n",
        "        input_layer_name = model_config['layers'][0]['name']\n",
        "    model_config['layers'][0] = {\n",
        "                        'name': input_layer_name,\n",
        "                        'class_name': 'InputLayer',\n",
        "                        'config': {\n",
        "                            'batch_input_shape': new_shape,\n",
        "                            'dtype': 'float32',\n",
        "                            'sparse': False,\n",
        "                            'name': input_layer_name\n",
        "                        },\n",
        "                        'inbound_nodes': []\n",
        "                    }\n",
        "    model_config['layers'][1]['inbound_nodes'] = [[[input_layer_name, 0, 0, {}]]]\n",
        "    model_config['input_layers'] = [[input_layer_name, 0, 0]] \n",
        "    # Create new model\n",
        "    new_model = model.__class__.from_config(model_config, custom_objects={})\n",
        "    # Copy weights\n",
        "    weights = [layer.get_weights() for layer in model.layers[1:]]\n",
        "    for layer, weight in zip(new_model.layers[1:], weights):\n",
        "        layer.set_weights(weight)\n",
        "\n",
        "    return new_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0vGbMh1Xz9S"
      },
      "source": [
        "#  Feed forward networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJEXli57O1i1"
      },
      "source": [
        "def model_0_pet(input_shape = pet_shape):\n",
        "\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "    \n",
        "    x = tf.keras.layers.Conv3D(filters=32, kernel_size=5, activation=\"relu\")(inputs)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=256, activation=\"relu\")(x)\n",
        "    \n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "   \n",
        "    model = tf.keras.Model(inputs, outputs, name=\"model_0_pet\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def model_1_pet(input_shape = pet_shape):\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "    \n",
        "    x = Conv3D(filters=32, kernel_size=5, activation=\"relu\")(inputs)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "    \n",
        "    x = Conv3D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=256, activation=\"relu\")(x)\n",
        "    x = Dense(units=256, activation=\"relu\")(x)\n",
        "    \n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs, outputs, name=\"model_1_pet\")\n",
        "    return model\n",
        "\n",
        "def best_model_pet(input_shape = pet_shape):\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    x = Conv3D(filters=16, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(inputs)\n",
        "    x = Conv3D(filters=16, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = BatchNormalization(momentum=0.9)(x)\n",
        "    x = Conv3D(filters=128, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = Conv3D(filters=128, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = Conv3D(filters=128, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = MaxPooling3D(pool_size=2, strides=2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    x = Dense(units=256, activation='relu')(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "\n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"model_4_pet\")\n",
        "    return model\n",
        "\n",
        "def best_model_mri(input_shape = mri_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    x = Conv3D(filters=32, kernel_size=5, activation='relu')(inputs)\n",
        "    x = Conv3D(filters=32, kernel_size=5, activation='relu')(x) \n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "    x = Conv3D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = BatchNormalization(momentum=0.9)(x)\n",
        "    x = Conv3D(filters=128, kernel_size=3, activation='relu')(x)\n",
        "    x = Conv3D(filters=128, kernel_size=3, activation='relu')(x)\n",
        "    x = Conv3D(filters=128, kernel_size=3, activation='relu')(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = BatchNormalization(momentum=0.9)(x)\n",
        "    x = Conv3D(filters=256, kernel_size=3, activation='relu')(x)\n",
        "    x = Conv3D(filters=256, kernel_size=3, activation='relu')(x)\n",
        "    x = Conv3D(filters=256, kernel_size=3, activation='relu')(x)\n",
        "    x = GlobalAveragePooling3D()(x)\n",
        "\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    x = Dense(units=256, activation='relu')(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    x = Dense(units=128, activation='relu')(x)\n",
        "\n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"model_4_mri\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjzZZNQRX4Ax"
      },
      "source": [
        "# ResNets 3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWTG6058gnw4"
      },
      "source": [
        "# This code is an adaptation of https://github.com/raghakot/keras-resnet/blob/master/resnet.py \n",
        "# to 3D\n",
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\n",
        "        \"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv3D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, kernel_initializer=kernel_initializer,\n",
        "                      padding=padding,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv3D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, kernel_initializer=kernel_initializer,\n",
        "                      padding=padding,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = ceil(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS])\n",
        "    stride_height = ceil(input_shape[COL_AXIS] / residual_shape[COL_AXIS])\n",
        "    stride_depth = ceil(input_shape[DEPTH_AXIS] / residual_shape[DEPTH_AXIS])\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or stride_depth > 1 \\\n",
        "            or not equal_channels:\n",
        "        shortcut = Conv3D(\n",
        "            filters=residual_shape[CHANNEL_AXIS],\n",
        "            kernel_size=(1, 1, 1),\n",
        "            strides=(stride_width, stride_height, stride_depth),\n",
        "            kernel_initializer=\"he_normal\", padding=\"valid\",\n",
        "            kernel_regularizer=l2(1e-4)\n",
        "            )(input)\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, kernel_regularizer, repetitions,\n",
        "                      is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            strides = (1, 1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                strides = (2, 2, 2)\n",
        "            input = block_function(filters=filters, strides=strides,\n",
        "                                   kernel_regularizer=kernel_regularizer,\n",
        "                                   is_first_block_of_first_layer=(\n",
        "                                       is_first_layer and i == 0)\n",
        "                                   )(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
        "                is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n",
        "                           strides=strides, padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=kernel_regularizer\n",
        "                           )(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters,\n",
        "                                    kernel_size=(3, 3, 3),\n",
        "                                    strides=strides,\n",
        "                                    kernel_regularizer=kernel_regularizer\n",
        "                                    )(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3, 3),\n",
        "                                   kernel_regularizer=kernel_regularizer\n",
        "                                   )(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
        "               is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv3D(filters=filters, kernel_size=(1, 1, 1),\n",
        "                              strides=strides, padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=kernel_regularizer\n",
        "                              )(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1, 1),\n",
        "                                       strides=strides,\n",
        "                                       kernel_regularizer=kernel_regularizer\n",
        "                                       )(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3, 3),\n",
        "                                   kernel_regularizer=kernel_regularizer\n",
        "                                   )(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1, 1),\n",
        "                                   kernel_regularizer=kernel_regularizer\n",
        "                                   )(conv_3_3)\n",
        "\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "def _handle_data_format():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global DEPTH_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        DEPTH_AXIS = 3\n",
        "        CHANNEL_AXIS = 4\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "        DEPTH_AXIS = 4\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class ResnetBuilder(object):\n",
        "    \"\"\"ResNet.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_data_format()\n",
        "        if len(input_shape) != 4:\n",
        "            raise ValueError(\"Input should have 4 dimensions\")\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7, 7), strides=(2, 2, 2), kernel_regularizer=l2(reg_factor))(input)\n",
        "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\")(conv1)\n",
        "\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, kernel_regularizer=l2(reg_factor), repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # last activation\n",
        "        block = _bn_relu(block)\n",
        "        block_shape = K.int_shape(block)\n",
        "\n",
        "        # Classifier block\n",
        "        pool2 = GlobalAveragePooling3D()(block)\n",
        "        # flatten1 = Flatten()(pool2)\n",
        "        if num_outputs > 1:\n",
        "            dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\", activation=\"softmax\", kernel_regularizer=l2(reg_factor))(pool2)\n",
        "        else:\n",
        "            dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\", activation=\"sigmoid\", kernel_regularizer=l2(reg_factor))(pool2)\n",
        "\n",
        "        model = tf.keras.Model(inputs=input, outputs=dense)\n",
        "        return model\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet(num_layers, input_shape, num_outputs, reg_factor=1e-4):\n",
        "        \"\"\"Build resnet 18, 34, 50, 101 or 152\"\"\"\n",
        "\n",
        "        repetitions = {18: [2, 2, 2, 2], \n",
        "                       34: [3, 4, 6, 3],\n",
        "                       50: [3, 4, 6, 3],\n",
        "                       101: [2, 4, 23, 3],\n",
        "                       152: [3, 8, 36, 3]}\n",
        "\n",
        "        block_fn = {18: basic_block, 34: basic_block, 50: bottleneck,\n",
        "                    101: bottleneck, 152:bottleneck}\n",
        "\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, block_fn[num_layers],\n",
        "                                     repetitions[num_layers], reg_factor=reg_factor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsUSjQ5eYJtK"
      },
      "source": [
        "# Pretrained ResNet for transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N1pAUUcXkdm"
      },
      "source": [
        "# Build pretrained resnet for transfer learning\n",
        "def build_pretrained_resnet18(input_shape = mri_shape, include_top = False):\n",
        "    # Load pretrained model\n",
        "    drive.mount('/content/drive') \n",
        "    pretrained_resnet18 = tf.keras.models.load_model('/content/drive/MyDrive/pretrained_models/pretrained_3D_resnet18.h5')\n",
        "    # Delete classifier\n",
        "    pretrained_resnet18 = Model(pretrained_resnet18.input, pretrained_resnet18.layers[-2].output)\n",
        "    # Change input shape\n",
        "    pretrained_resnet18 = change_input_shape(pretrained_resnet18, input_shape, name='new_input')\n",
        "    pretrained_resnet18.trainable = False\n",
        "    inputs = Input(shape=input_shape, name='mri_input')\n",
        "    features = pretrained_resnet18(inputs, training=False)\n",
        "    outputs = Dense(3)(features)\n",
        "    pretrained_resnet18 = Model(inputs, outputs)\n",
        "\n",
        "    return pretrained_resnet18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5pr6gygYSoC"
      },
      "source": [
        "# Two inputs model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxawWFGKYVxu"
      },
      "source": [
        "# Model with two inputs\n",
        "def build_two_input_model(pet_shape = pet_shape, mri_shape = mri_shape):\n",
        "\n",
        "    # Base pet model\n",
        "    pet_model = best_model_pet(pet_shape)\n",
        "    # Delete classifier\n",
        "    pet_model = Model(pet_model.input, pet_model.layers[-2].output)\n",
        "    # Input for pet images\n",
        "    pet_input = Input(shape=pet_shape, name='pet_input')\n",
        "    pet_features = pet_model(pet_input)\n",
        "\n",
        "    # Base mri model\n",
        "    mri_model = best_model_mri(mri_shape)\n",
        "    # Delete classifier\n",
        "    mri_model = Model(mri_model.input, mri_model.layers[-2].output)\n",
        "    print(mri_model.summary())\n",
        "    # Input for mri images\n",
        "    mri_input = Input(shape=mri_shape, name='mri_input')\n",
        "    mri_features = mri_model(mri_input)\n",
        "\n",
        "    # Two inputs model\n",
        "    x = concatenate([pet_features, mri_features])\n",
        "    pred = Dense(3, name='label')(x)\n",
        "    model = Model(inputs=[pet_input, mri_input], outputs = [pred])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}