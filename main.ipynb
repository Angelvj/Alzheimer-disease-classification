{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copia de Copia de main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelvj/TFG/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA36tehHryhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174a7472-6aeb-4d71-ca86-42d1acaeece1"
      },
      "source": [
        "# Imports\n",
        "!pip install -q -U keras-tuner\n",
        "import kerastuner as kt\n",
        "\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras as k\n",
        "import sklearn\n",
        "import nibabel as nib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, MaxPool3D, GlobalAveragePooling3D, AveragePooling3D\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import time\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier \n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import decomposition\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCMEYyQ-UYaS"
      },
      "source": [
        "# Load data and impute NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZf1JmliAMNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b23e0eb-0fb5-45da-aec3-4f167742f538"
      },
      "source": [
        "# Load data\n",
        "COLAB = True\n",
        "preprocessed = True\n",
        "\n",
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  DATA_PATH = '/content/drive/My Drive/Machine learning/data'\n",
        "  if preprocessed:\n",
        "      DATA_PATH += '/preprocessed'\n",
        "\n",
        "else: \n",
        "  DATA_PATH = '../../data'\n",
        "\n",
        "def load_image(filename):    \n",
        "    \"\"\"\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        relative path to de image\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    img : numpy ndarray\n",
        "        array containing the image\n",
        "        \n",
        "    \"\"\"\n",
        "    img = nib.load(filename)\n",
        "    img = np.asarray(img.dataobj)\n",
        "    img = np.expand_dims(img, axis=3)\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_images_from_dir(dirname):\n",
        "    \"\"\"\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dirname : str\n",
        "        name of the directory containing images.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    imgs : numpy ndarray\n",
        "        array containing all of the images in the folder.\n",
        "\n",
        "    \"\"\"\n",
        "    imgs = []\n",
        "\n",
        "    for filename in tqdm(glob.glob(dirname + '/*.nii')):\n",
        "        imgs.append(load_image(filename))\n",
        "        \n",
        "    imgs = np.stack(imgs) # All images over the new first dimension\n",
        "    return imgs\n",
        "\n",
        "def load_data(dirs_dict, categorical = False):\n",
        "    \"\"\"\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dirs_dict : dictionary\n",
        "        dictionary containing data folders name, and the label for the images\n",
        "        on each forlder.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    x : numpy ndarray\n",
        "        array containing the images.\n",
        "    y : numpy ndarray\n",
        "\n",
        "        array containig the label of each image.\n",
        "\n",
        "    \"\"\"\n",
        "    first = True\n",
        "    for key, value in dirs_dict.items():\n",
        "        if first:\n",
        "            X = load_images_from_dir(value)\n",
        "            # ¿necesario float32 o puedo usar uint8?\n",
        "            y = np.full((X.shape[0]), key, dtype=np.float32)\n",
        "            first = False\n",
        "        else:\n",
        "            X_current = load_images_from_dir(value)\n",
        "            X = np.concatenate((X, X_current), axis=0)\n",
        "            y = np.concatenate((y, np.full((X_current.shape[0]), key, dtype=np.float32)), axis=0)\n",
        "            \n",
        "    if categorical:\n",
        "        y = k.utils.to_categorical(y)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "def impute_nan_values(imgs, inplace=True):\n",
        "    # Replace nan values with 0\n",
        "    return np.nan_to_num(imgs, copy = not inplace)\n",
        "\n",
        "# Load PET images with labels\n",
        "print('\\n --- Loading PET data --- \\n')\n",
        "time.sleep(0.5)\n",
        "X, y = load_data({0: DATA_PATH + \"/ppNOR/PET\", \n",
        "                  1: DATA_PATH + \"/ppAD/PET\",\n",
        "                  2: DATA_PATH + \"/ppMCI/PET\"})\n",
        "\n",
        "# Separate into training and test sets (stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.2, stratify = y, random_state = 1)\n",
        "\n",
        "impute_nan_values(X_train)\n",
        "impute_nan_values(X_test)\n",
        "\n",
        "print('\\n --- PET data loaded --- \\n')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            " --- Loading PET data --- \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [01:03<00:00,  1.07it/s]\n",
            "100%|██████████| 70/70 [01:11<00:00,  1.02s/it]\n",
            "100%|██████████| 111/111 [01:45<00:00,  1.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " --- PET data loaded --- \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf_tgVdodQ6E"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm7JaiUnr7ZI"
      },
      "source": [
        "def max_intensity_normalization(X, percentage, inplace=True):\n",
        "\n",
        "    if not inplace:\n",
        "        X = X.copy()\n",
        "\n",
        "    volume_shape = X[0].shape\n",
        "    n_max_values = int((volume_shape[0]*volume_shape[1]*volume_shape[2]*percentage)/100)\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        n_max_idx = np.unravel_index((X[i]).argsort(axis=None)[-n_max_values:], X[i].shape)\n",
        "        mean = np.mean(X[i][n_max_idx])\n",
        "        X[i] /= mean\n",
        "\n",
        "    if not inplace:\n",
        "        return X\n",
        "\n",
        "X_train_n = max_intensity_normalization(X_train, 1, inplace=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G7pRWJVGpmK"
      },
      "source": [
        "# Testing SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLuS8qfUkHAe"
      },
      "source": [
        "# # Test SVM classifier first\n",
        "# x_tr, x_val, y_tr, y_val = train_test_split(X_train_n, y_train, test_size = 0.2, stratify = y_train)\n",
        "\n",
        "# x_tr_1D = np.empty((x_tr.shape[0], x_tr.shape[1]*x_tr.shape[2]*x_tr.shape[3]))\n",
        "\n",
        "# # Convert each image to a single dimension ndarray\n",
        "# for i in range(len(x_tr)):\n",
        "#     x_tr_1D[i] = x_tr[i].flatten()\n",
        "\n",
        "# x_val_1D = np.empty((x_val.shape[0], x_val.shape[1]*x_val.shape[2]*x_val.shape[3]))\n",
        "# for i in range(len(y_val)):\n",
        "#     x_val_1D[i] = x_val[i].flatten()\n",
        "\n",
        "# # clf = svm.SVC(kernel='linear', C=0.8)\n",
        "# # clf = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5, C=0.05)) # 0.48 en 5 tiradas\n",
        "# # clf.fit(x_tr_1D, y_tr)\n",
        "\n",
        "# print(clf.score(x_tr_1D, y_tr))\n",
        "# print(clf.score(x_val_1D, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gMXCMkfGymI"
      },
      "source": [
        "# Functions for training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQFcE3TcwW3m"
      },
      "source": [
        "def learning_curve(hist):\n",
        "    history_dict = hist.history\n",
        "    loss = history_dict['loss']\n",
        "    val_loss = history_dict['val_loss']\n",
        "    plt.plot(loss)\n",
        "    plt.plot(val_loss)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylim(0 - 0.1, 6 + 0.1)\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.show()\n",
        "\n",
        "    acc = hist.history['accuracy']\n",
        "    val_acc = hist.history['val_accuracy']\n",
        "    plt.plot(acc)\n",
        "    plt.plot(val_acc)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylim(0 -0.1, 1 + 0.1)\n",
        "    plt.legend(['Training','Validation'])\n",
        "    plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yCcZQKccaYm"
      },
      "source": [
        "def cross_validate(model, x_train, y_train, num_folds, opt, batch_size, epochs, verbose=0, show_history=False, return_results=True, show_mean_history=True):\n",
        "\n",
        "    # Creamos un objeto kfold, especificando el número de segmentos que queremos utilizar,\n",
        "    # además utilizamos shuffle true, para que los num_folds conjuntos disjuntos se seleccionen\n",
        "    # de forma aleatoria, evitando de esta forma problemas que podría haber si los datos\n",
        "    # estuvieran ordenados siguiendo una cierta distribución\n",
        "\n",
        "    skfold = StratifiedKFold(n_splits = num_folds, shuffle=True)\n",
        "\n",
        "    model.compile(loss = k.losses.categorical_crossentropy, optimizer=opt,\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "    initial_weights = model.get_weights()\n",
        "\n",
        "    acc_per_fold = []\n",
        "    loss_per_fold = []\n",
        "    acc_per_fold_tr = []\n",
        "    loss_per_fold_tr = []\n",
        "\n",
        "    fold_no = 1\n",
        "\n",
        "    mean_history = np.zeros((4, epochs))\n",
        "\n",
        "    for kfold_train, kfold_test in skfold.split(x_train, y_train):\n",
        "\n",
        "        # En cada fold, comenzamos con los pesos iniciales. Tratamos de que las 5\n",
        "        # folds sean lo más independientes posible.\n",
        "        model.set_weights(initial_weights)\n",
        "\n",
        "        if verbose:\n",
        "            print('------------------------------------------------------------------------')\n",
        "            print(f'Entrenando para el fold {fold_no} ...')\n",
        "\n",
        "        history = model.fit(x_train[kfold_train], \n",
        "                            k.utils.to_categorical(y_train[kfold_train]), \n",
        "                            batch_size= batch_size,\n",
        "                            epochs=epochs, verbose = verbose, \n",
        "                            validation_data = (x_train[kfold_test], k.utils.to_categorical(y_train[kfold_test]))\n",
        "                            )\n",
        "\n",
        "        if show_history:\n",
        "            # Mostramos la evolución en cada fold\n",
        "            learning_curve(history)\n",
        "\n",
        "        if show_mean_history:\n",
        "            mean_history[0] += history.history['loss']\n",
        "            mean_history[1] += history.history['val_loss']\n",
        "            mean_history[2] += history.history['accuracy']\n",
        "            mean_history[3] += history.history['val_accuracy']\n",
        "\n",
        "        # Calculamos la bondad del modelo para el fold reservado para testing\n",
        "        scores = model.evaluate(x_train[kfold_test], k.utils.to_categorical(y_train[kfold_test]), verbose=0)\n",
        "        scores_train = model.evaluate(x_train[kfold_train], k.utils.to_categorical(y_train[kfold_train]), verbose=0)\n",
        "\n",
        "        # Vamos guardando el accuracy y pérdida para cada fold\n",
        "        acc_per_fold.append(scores[1])\n",
        "        loss_per_fold.append(scores[0])\n",
        "\n",
        "        acc_per_fold_tr.append(scores_train[1])\n",
        "        loss_per_fold_tr.append(scores_train[0])\n",
        "\n",
        "        if verbose:\n",
        "            print(f'Resultado para el fold {fold_no}: {model.metrics_names[0]} de {scores[0]}; {model.metrics_names[1]} de {scores[1]*100}%')\n",
        "\n",
        "        fold_no += 1\n",
        "\n",
        "    # ==  Mostramos los resultados para cada fold == \n",
        "    if verbose:\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print('Resultados por cada fold')\n",
        "        for i in range(0, len(acc_per_fold)):\n",
        "            print('------------------------------------------------------------------------')\n",
        "            print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Media de los resultados, por época:')\n",
        "    if show_mean_history:\n",
        "        plt.plot(mean_history[0]/num_folds)\n",
        "        plt.plot(mean_history[1]/num_folds)\n",
        "        plt.ylabel('Mean loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylim(0 - 0.1, 6 + 0.1)\n",
        "        plt.legend(['Training', 'Validation'])\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(mean_history[2]/num_folds)\n",
        "        plt.plot(mean_history[3]/num_folds)\n",
        "        plt.ylabel('Mean accuracy')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylim(0 -0.1, 1 + 0.1)\n",
        "        plt.legend(['Training','Validation'])\n",
        "        plt.show()\n",
        "\n",
        "    # Calculamos y mostramos los valores medios\n",
        "    mean_acc_cv = np.mean(acc_per_fold)\n",
        "    mean_loss_cv = np.mean(loss_per_fold)\n",
        "    mean_acc_tr = np.mean(acc_per_fold_tr)\n",
        "    mean_loss_tr = np.mean(loss_per_fold_tr)\n",
        "\n",
        "    if not return_results:\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print('Media de los resultados para todos los folds:')\n",
        "        print(f'> Accuracy: {np.mean(acc_per_fold)}')\n",
        "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "        print(f'> Train accuracy: {np.mean(acc_per_fold_tr)}')\n",
        "        print(f'> Train accuracy: {np.mean(loss_per_fold_tr)}')\n",
        "        print('------------------------------------------------------------------------')\n",
        "\n",
        "    else:\n",
        "        return mean_acc_tr, mean_loss_tr, mean_acc_cv, mean_loss_cv"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFxaFXjCsE9n",
        "outputId": "b05c2018-63b9-4d2e-9fed-173e784caee6"
      },
      "source": [
        "!rm -r ./basic\\_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './basic_model': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlk5X7zs06eG"
      },
      "source": [
        "# Hypertuning models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9lmY8gvDklb"
      },
      "source": [
        "class MyTuner(kt.tuners.BayesianOptimization):\n",
        "  def run_trial(self, trial, *args, **kwargs):\n",
        "    # kwargs['batch_size'] = trial.hyperparameters.Choice('batch_size', values=[4, 8, 16])\n",
        "    super(MyTuner, self).run_trial(trial, *args, **kwargs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGPY9CN30_Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d0e014-4bb2-4fe3-d4e2-d8e28e719680"
      },
      "source": [
        "'''\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is 256. The optimal number of filters in the convolutional layer is 32. The optimal learning \n",
        "rate for the optimizer is 0.0001. The optimal batch size is 4\n",
        "'''\n",
        "def model_zero_builder(hp, width=79, height=95, depth=68):\n",
        "     \n",
        "    model = keras.Sequential()\n",
        "\n",
        "    hp_filters = hp.Choice('filters', values = [8, 16, 32, 64])\n",
        "    model.add(Conv3D(filters=hp_filters, kernel_size=3, activation=\"relu\", input_shape = (width, height, depth, 1)))\n",
        "    model.add(MaxPooling3D(pool_size=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    hp_units = hp.Choice('units', values=[64, 128, 256])\n",
        "    model.add(Dense(units=hp_units, activation=\"relu\"))\n",
        "\n",
        "    model.add(Dense(units=3, activation=\"softmax\"))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5, 1e-6])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss = keras.losses.categorical_crossentropy,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# tuner = MyTuner(model_zero_builder, \n",
        "#                 objective='val_loss',\n",
        "#                 project_name = 'model_zero',\n",
        "#                 max_trials = 100)\n",
        "\n",
        "# tuner.search(X_train_n, k.utils.to_categorical(y_train), epochs=30, validation_split=0.2)\n",
        "\n",
        "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# print(f\"\"\"\n",
        "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "# layer is {best_hps.get('units')}. The optimal number of filters in the convolutional layer is\n",
        "# {best_hps.get('filters')}. The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
        "#  The optimal batch size is {best_hps.get('batch_size')}\n",
        "# \"\"\")\n",
        "\n",
        "\n",
        "def model_two_builder(hp, width=79, height=95, depth=68):\n",
        "    inputs = k.Input((width, height, depth, 1))\n",
        "\n",
        "    hp_filter_size_1 = hp.Choice('ks_1', values=[3,5])\n",
        "    hp_filters_1 = hp.Choice('filters_1', values=[16, 32])\n",
        "    x = Conv3D(filters=hp_filters_1, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    hp_filter_size_2 = hp.Choice('ks_2', values=[3,5])\n",
        "    hp_filters_2 = hp.Choice('filters_2', values=[32, 64])\n",
        "    x = Conv3D(filters=hp_filters_2, kernel_size=hp_filter_size_2, activation=\"relu\")(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    hp_filter_size_3 = hp.Choice('ks_3', values=[3,5])\n",
        "    hp_filters_3 = hp.Choice('filters_3', values=[32, 64, 128])\n",
        "    x = Conv3D(filters=hp_filters_3, kernel_size=hp_filter_size_3, activation=\"relu\")(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    hp_units = hp.Choice('units', values=[64, 128, 256])\n",
        "    x = Dense(units=hp_units, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "    model = k.Model(inputs, outputs, name=\"second_model_builder\")\n",
        "\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss = keras.losses.categorical_crossentropy,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "tuner = MyTuner(model_two_builder, \n",
        "                objective='val_loss',\n",
        "                project_name = 'model_two',\n",
        "                max_trials = 150)\n",
        "\n",
        "tuner.search(X_train_n, k.utils.to_categorical(y_train), epochs=30, validation_split=0.2)\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. Optimal no. filters: {best_hps.get('filters_1')},\n",
        "{best_hps.get('filters_2')}, {best_hps.get('filters_3')}. Optimal filter's size:\n",
        "{best_hps.get('ks_1')}, {best_hps.get('ks_2')}, {best_hps.get('ks_3')}. Optimal\n",
        "units in fully connected: {best_hps.get('units')}\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 119 Complete [00h 00m 55s]\n",
            "val_loss: 0.8455232381820679\n",
            "\n",
            "Best val_loss So Far: 0.8149768710136414\n",
            "Total elapsed time: 01h 56m 07s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  _check_optimize_result(\"lbfgs\", opt_res)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #120\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "ks_1              |5                 |5                 \n",
            "filters_1         |16                |16                \n",
            "ks_2              |5                 |5                 \n",
            "filters_2         |64                |64                \n",
            "ks_3              |5                 |5                 \n",
            "filters_3         |128               |128               \n",
            "units             |256               |256               \n",
            "\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 1.1062 - accuracy: 0.3712 - val_loss: 1.0722 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 1.0942 - accuracy: 0.3929 - val_loss: 1.0743 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 1.0876 - accuracy: 0.3947 - val_loss: 1.0559 - val_accuracy: 0.5000\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 1.0764 - accuracy: 0.4268 - val_loss: 1.0395 - val_accuracy: 0.5000\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 1.0800 - accuracy: 0.4263 - val_loss: 1.0469 - val_accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 1.0611 - accuracy: 0.4545 - val_loss: 1.0456 - val_accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 2s 353ms/step - loss: 1.0761 - accuracy: 0.4151 - val_loss: 1.0524 - val_accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 1.0641 - accuracy: 0.4428 - val_loss: 1.0334 - val_accuracy: 0.5000\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 2s 349ms/step - loss: 1.0834 - accuracy: 0.3977 - val_loss: 1.0472 - val_accuracy: 0.5000\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 1.0678 - accuracy: 0.4216 - val_loss: 1.0370 - val_accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 1.0516 - accuracy: 0.4515 - val_loss: 1.0322 - val_accuracy: 0.5000\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 1.0468 - accuracy: 0.4467 - val_loss: 1.0232 - val_accuracy: 0.5000\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 1.0365 - accuracy: 0.4323 - val_loss: 1.0267 - val_accuracy: 0.5250\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 2s 349ms/step - loss: 1.0258 - accuracy: 0.4936 - val_loss: 0.9908 - val_accuracy: 0.5000\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 2s 353ms/step - loss: 1.0028 - accuracy: 0.4298 - val_loss: 1.0132 - val_accuracy: 0.5250\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 1.0027 - accuracy: 0.5493 - val_loss: 0.9772 - val_accuracy: 0.5000\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 0.9833 - accuracy: 0.4634 - val_loss: 0.9647 - val_accuracy: 0.5000\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 0.9542 - accuracy: 0.4597 - val_loss: 0.9416 - val_accuracy: 0.4250\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 0.8835 - accuracy: 0.5334 - val_loss: 0.9160 - val_accuracy: 0.5000\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 0.8998 - accuracy: 0.5583 - val_loss: 1.0424 - val_accuracy: 0.4500\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 0.9051 - accuracy: 0.5233 - val_loss: 0.9166 - val_accuracy: 0.3500\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 0.8507 - accuracy: 0.5877 - val_loss: 0.8977 - val_accuracy: 0.4250\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 2s 353ms/step - loss: 0.7851 - accuracy: 0.6651 - val_loss: 0.9271 - val_accuracy: 0.5250\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 0.7706 - accuracy: 0.5636 - val_loss: 0.9923 - val_accuracy: 0.4500\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 0.8665 - accuracy: 0.5626 - val_loss: 0.9536 - val_accuracy: 0.4500\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 0.8372 - accuracy: 0.5899 - val_loss: 0.9104 - val_accuracy: 0.4250\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 0.8172 - accuracy: 0.5956 - val_loss: 0.9002 - val_accuracy: 0.5000\n",
            "Epoch 28/30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8pheYdBfhuR"
      },
      "source": [
        "# Define models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "__EGiOvl5IjU",
        "outputId": "8e84c5a2-f254-4db3-b323-90cc2d9c0174"
      },
      "source": [
        "# CNN MODELS\n",
        "\n",
        "# Model configuration\n",
        "sample_shape = (79,95,68,1)\n",
        "no_classes = 3\n",
        "\n",
        "def get_model_zero(width=79, height=95, depth=68):\n",
        "    # Training time (10-fold): 5s per epoch\n",
        "    # 10-fold cross validation results:\n",
        "    #                   Val_accuracy                Val_loss                Tr_accuracy         Tr_loss\n",
        "    # With dropout      0.46842105090618136         1.6831728219985962      0.9446927368640899  0.11225743502145633\n",
        "    # No dropout        0.473157899081707           1.5029887318611146      1.0                 0.0027088650298537687           \n",
        "    # No drop. 64u      \n",
        "\n",
        "    inputs = k.Input((width, height, depth, 1))\n",
        "\n",
        "    x = Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "\n",
        "    x = MaxPooling3D(pool_size=2)(x)  \n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=256, activation=\"relu\")(x) \n",
        "    # x = Dropout(0.5)(x)\n",
        "\n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "    model = k.Model(inputs, outputs, name=\"model_0\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_model_one(width=79, height=95, depth=68):\n",
        "    # Training time: 2s per epoch\n",
        "    # 10-fold cross validation results:\n",
        "    # Val_accuracy          Val_loss                Tr_accuracy     Tr_loss\n",
        "    # 0.5028947353363037    1.8094949841499328      1.0             0.001150345930363983\n",
        "\n",
        "    inputs = k.Input((width, height, depth, 1))\n",
        "\n",
        "    x = Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "\n",
        "    x = MaxPooling3D(pool_size=2)(x)  \n",
        "\n",
        "    x = Conv3D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=256, activation=\"relu\")(x) \n",
        "\n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "    model = k.Model(inputs, outputs, name=\"model_1\")\n",
        "    return model\n",
        "\n",
        "def get_second_model(width=79, height=95, depth=68):\n",
        "    inputs = k.Input((width, height, depth, 1))\n",
        "\n",
        "    x = Conv3D(filters=8, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv3D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = Conv3D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = MaxPooling3D(pool_size=2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=256, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "    model = k.Model(inputs, outputs, name=\"model_2\")\n",
        "    return model\n",
        "\n",
        "# Fit model to data\n",
        "# Batch size of 16 as a standard starting point: https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/ ?\n",
        "\n",
        "print('\\n --------------- MODELO 0 ------------------\\n')\n",
        "# Ya tiene los mejores hiperparámetros ajustados\n",
        "model = get_model_zero()\n",
        "model.summary()\n",
        "results = cross_validate(model, X_train_n, y_train, 10, k.optimizers.Adam(lr=0.0001), 4, 50, \n",
        "               verbose = 1, show_history = True)\n",
        "print(results)\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# print('\\n --------------- MODELO 1 ------------------\\n')\n",
        "# # Ya tiene los mejores hiperparámetros ajustados\n",
        "# model = get_model_one()\n",
        "# model.summary()\n",
        "# results = cross_validate(model, X_train_n, y_train, 10, k.optimizers.Adam(lr=0.0001), 4, 10, \n",
        "#                verbose = 1, show_history = True)\n",
        "# print(results)\n",
        "# keras.backend.clear_session()\n",
        "\n",
        "# print('\\n --------------- MODELO 2 ------------------\\n')\n",
        "# model = get_second_model()\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# results = cross_validate(model, X_train_n, y_train, 10, k.optimizers.Adam(lr=0.0001), 4, 50, \n",
        "#                verbose = 1, show_history = True)\n",
        "\n",
        "# keras.backend.clear_session()\n",
        "\n",
        "\n",
        "# print('\\n --------------- MODELO 3 ------------------\\n')\n",
        "# model = get_model(3)\n",
        "# model.summary()\n",
        "\n",
        "# # opt = SGD(lr = 0.001, momentum = 0.9, nesterov = True)\n",
        "# results = cross_validate(model, X_train_n, y_train, 5,  k.optimizers.Adam(), 16, 30, \n",
        "#                verbose = 1, show_history = False)\n",
        "# print(results)\n",
        "# keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " --------------- MODELO 0 ------------------\n",
            "\n",
            "Model: \"model_0\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 79, 95, 68, 1)]   0         \n",
            "_________________________________________________________________\n",
            "conv3d (Conv3D)              (None, 77, 93, 66, 32)    896       \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 38, 46, 33, 32)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1845888)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               472547584 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 472,549,251\n",
            "Trainable params: 472,549,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Entrenando para el fold 1 ...\n",
            "Epoch 1/50\n",
            "45/45 [==============================] - 8s 124ms/step - loss: 11.3245 - accuracy: 0.3640 - val_loss: 3.8229 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 2.4603 - accuracy: 0.2919 - val_loss: 2.0601 - val_accuracy: 0.2500\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 1.3961 - accuracy: 0.3469 - val_loss: 1.7940 - val_accuracy: 0.2500\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 1.2684 - accuracy: 0.4607 - val_loss: 1.1711 - val_accuracy: 0.3500\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 1.0451 - accuracy: 0.5319 - val_loss: 1.3133 - val_accuracy: 0.3500\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 1.2156 - accuracy: 0.4126 - val_loss: 1.1690 - val_accuracy: 0.4500\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.9771 - accuracy: 0.5348 - val_loss: 1.3502 - val_accuracy: 0.3000\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 1.1716 - accuracy: 0.5399 - val_loss: 1.1853 - val_accuracy: 0.3500\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 5s 111ms/step - loss: 0.8427 - accuracy: 0.6321 - val_loss: 2.1955 - val_accuracy: 0.4500\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.9180 - accuracy: 0.5736 - val_loss: 1.5357 - val_accuracy: 0.4500\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.7298 - accuracy: 0.7028 - val_loss: 1.6210 - val_accuracy: 0.4500\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.6965 - accuracy: 0.6991 - val_loss: 1.1529 - val_accuracy: 0.3500\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.6385 - accuracy: 0.7019 - val_loss: 1.0687 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.4252 - accuracy: 0.9087 - val_loss: 1.0975 - val_accuracy: 0.4500\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.4381 - accuracy: 0.8715 - val_loss: 1.1270 - val_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.3680 - accuracy: 0.9116 - val_loss: 1.0892 - val_accuracy: 0.4500\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.2412 - accuracy: 0.9728 - val_loss: 1.3588 - val_accuracy: 0.4500\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.2498 - accuracy: 0.9401 - val_loss: 1.0393 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.1534 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.1131 - accuracy: 1.0000 - val_loss: 1.2371 - val_accuracy: 0.4000\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.1223 - accuracy: 0.9760 - val_loss: 1.0858 - val_accuracy: 0.5500\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 5s 112ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 1.5811 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.1699 - accuracy: 0.9680 - val_loss: 1.1363 - val_accuracy: 0.4000\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 5s 112ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 1.1409 - val_accuracy: 0.4000\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 1.0479 - val_accuracy: 0.5500\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.6000\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 1.0479 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.0920 - val_accuracy: 0.5500\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.4500\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.0619 - val_accuracy: 0.5500\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.0853 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.1071 - val_accuracy: 0.5500\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 5s 115ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.1332 - val_accuracy: 0.4500\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.1261 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.2879 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1446 - val_accuracy: 0.5500\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1264 - val_accuracy: 0.5500\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.1931 - val_accuracy: 0.5500\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.1552 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1815 - val_accuracy: 0.5500\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 5s 112ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.1814 - val_accuracy: 0.5500\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1935 - val_accuracy: 0.5500\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1901 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1707 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.6000\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 5s 114ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.5500\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3346 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.5500\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Resultado para el fold 1: loss de 1.2126048803329468; accuracy de 60.00000238418579%\n",
            "------------------------------------------------------------------------\n",
            "Entrenando para el fold 2 ...\n",
            "Epoch 1/50\n",
            "45/45 [==============================] - 5s 113ms/step - loss: 5.2363 - accuracy: 0.3296 - val_loss: 1.2297 - val_accuracy: 0.5500\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 5s 110ms/step - loss: 1.1115 - accuracy: 0.4022 - val_loss: 1.0089 - val_accuracy: 0.4500\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9923 - accuracy: 0.4860"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVZyqIoOfGVx"
      },
      "source": [
        "# Models to be tested\n",
        "# def get_first_model(width=79, height=95, depth=68):\n",
        "#     '''\n",
        "#     Deeper model, \n",
        "#     '''\n",
        "#     inputs = k.Input((width, height, depth, 1))\n",
        "\n",
        "#     x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "#     # x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = MaxPooling3D(pool_size=2)(x)\n",
        "#     # x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "#     # x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = MaxPooling3D(pool_size=2)(x)\n",
        "#     # x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "#     # x = BatchNormalization()(x)\n",
        "\n",
        "#     x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = GlobalAveragePooling3D()(x)\n",
        "\n",
        "#     x = Dense(units=512, activation=\"relu\")(x)\n",
        "\n",
        "#     outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "#     model = k.Model(inputs, outputs, name=\"baseline_3Dcnn\")\n",
        "#     return model\n",
        "\n",
        "# def get_first_model(width=79, height=95, depth=68):\n",
        "#     \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "#     inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "#     x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "#     x = layers.MaxPool3D(pool_size=2)(x)\n",
        "#     x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "\n",
        "#     x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = layers.MaxPool3D(pool_size=2)(x)\n",
        "#     x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "\n",
        "#     x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = layers.MaxPool3D(pool_size=2)(x)\n",
        "#     x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "\n",
        "#     x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = layers.MaxPool3D(pool_size=2)(x)\n",
        "#     x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "\n",
        "#     x = layers.GlobalAveragePooling3D()(x)\n",
        "#     x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "#     x = layers.Dropout(0.3)(x)\n",
        "\n",
        "#     outputs = layers.Dense(units=3, activation=\"softmax\")(x)\n",
        "\n",
        "#     # Define the model.\n",
        "#     model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "#     return model\n",
        "\n",
        "\n",
        "# def get_fourth_model(width=79, height=95, depth=68):\n",
        "\n",
        "#     inputs = k.Input((width, height, depth, 1))\n",
        "\n",
        "#     x = Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "#     x = MaxPooling3D(pool_size=2)(x)\n",
        "#     x = Dropout(0.1)(x)\n",
        "\n",
        "#     x = Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = MaxPooling3D(pool_size=2)(x)\n",
        "#     x = Dropout(0.1)(x)\n",
        "\n",
        "#     x = Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "#     x = MaxPooling3D(pool_size=2)(x)\n",
        "#     x = Dropout(0.1)(x)\n",
        "\n",
        "#     x = Flatten()(x)\n",
        "#     x = Dense(units=256, activation=\"relu\")(x)\n",
        "#     x = Dropout(0.1)(x)\n",
        "\n",
        "#     outputs = Dense(units=3, activation=\"softmax\")(x)\n",
        "#     x = Dropout(0.5)(x)\n",
        "\n",
        "#     model = k.Model(inputs, outputs, name=\"baseline_3Dcnn\")\n",
        "#     return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}